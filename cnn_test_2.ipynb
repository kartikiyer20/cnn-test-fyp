{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import jax.numpy as jnp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "plt.figure(1, figsize=(3, 3))\n",
    "plt.imshow(digits.images[-1], cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_digits = len(digits.images)\n",
    "print(f\"Number of digits in the dataset: {num_digits}\")\n",
    "\n",
    "unique, counts = np.unique(digits.target, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "print(\"Class distribution:\", class_distribution)\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(10, 3))\n",
    "classes_to_view = [0, 1, 2, 3, 4]\n",
    "for i, cls in enumerate(classes_to_view):\n",
    "    idx = np.where(digits.target == cls)[0][0]\n",
    "    axs[i].imshow(digits.images[idx], cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    axs[i].set_title(f\"Class {cls}\")\n",
    "    axs[i].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering only few classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_keep = [0, 1, 3, 4]\n",
    "indices_to_keep = np.isin(digits.target, classes_to_keep)\n",
    "\n",
    "images = digits.images\n",
    "\n",
    "filtered_images = images[indices_to_keep]\n",
    "filtered_labels = digits.target[indices_to_keep]\n",
    "\n",
    "# Print the number of images and class distribution in the filtered dataset\n",
    "num_filtered_images = len(filtered_images)\n",
    "print(f\"Number of filtered images: {num_filtered_images}\")\n",
    "\n",
    "unique_filtered, counts_filtered = np.unique(filtered_labels, return_counts=True)\n",
    "filtered_class_distribution = dict(zip(unique_filtered, counts_filtered))\n",
    "print(\"Filtered class distribution:\", filtered_class_distribution)\n",
    "print(f\"filtered images shape: {filtered_images.shape}\")\n",
    "print(f\"filtered labels shape: {filtered_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filtered_images.reshape(-1, 8, 8, 1)\n",
    "label_encoder = LabelEncoder()\n",
    "Y = label_encoder.fit_transform(filtered_labels)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "print(\n",
    "    \"Class mapping:\",\n",
    "    dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=Y,\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "print(\"Y_test shape:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities for rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_grid_number(n, number):\n",
    "    if 1 <= number <= n**2:\n",
    "        row_index = (number - 1) // n + 1\n",
    "        column_index = (number - 1) % n + 1\n",
    "        return row_index, column_index\n",
    "    else:\n",
    "        raise ValueError(\"Number must be between 1 and n^2 inclusive.\")\n",
    "\n",
    "\n",
    "def grid_number(n, a, b):\n",
    "    if 1 <= a <= n and 1 <= b <= n:\n",
    "        return (a - 1) * n + b\n",
    "    else:\n",
    "        raise ValueError(\"Row and column indices must be between 1 and n inclusive.\")\n",
    "\n",
    "\n",
    "def reflection_grid(n, coordinates):\n",
    "    a, b = coordinates\n",
    "    reflected_b = n - b + 1\n",
    "    return a, reflected_b\n",
    "\n",
    "\n",
    "def rotation_grid(n, coordinates):\n",
    "    a, b = coordinates\n",
    "    rotated_a = n - b + 1\n",
    "    rotated_b = a\n",
    "    return rotated_a, rotated_b\n",
    "\n",
    "\n",
    "def rotate(n, number):\n",
    "    (a, b) = inverse_grid_number(n, number)\n",
    "    (new_a, new_b) = rotation_grid(n, (a, b))\n",
    "    return grid_number(n, new_a, new_b)\n",
    "\n",
    "\n",
    "def reflect(n, number):\n",
    "    (a, b) = inverse_grid_number(n, number)\n",
    "    (new_a, new_b) = reflection_grid(n, (a, b))\n",
    "    return grid_number(n, new_a, new_b)\n",
    "\n",
    "\n",
    "def generate_rotation_matrix(n):\n",
    "    # Define the size of the matrix\n",
    "    matrix_size = n**2\n",
    "\n",
    "    # Initialize a matrix with zeros\n",
    "    rotation_matrix = jnp.zeros((matrix_size, matrix_size), dtype=int)\n",
    "\n",
    "    # Set 1 at the specified positions for each column\n",
    "    for m in range(1, matrix_size + 1):\n",
    "        rotated_position = rotate(n, m)\n",
    "        rotation_matrix = rotation_matrix.at[rotated_position - 1, m - 1].set(\n",
    "            1\n",
    "        )  # Adjust for 0-based indexing\n",
    "\n",
    "    return rotation_matrix\n",
    "\n",
    "\n",
    "def generate_reflection_matrix(n):\n",
    "    # Define the size of the matrix\n",
    "    matrix_size = n**2\n",
    "\n",
    "    # Initialize a matrix with zeros\n",
    "    reflection_matrix = jnp.zeros((matrix_size, matrix_size), dtype=int)\n",
    "\n",
    "    # Set 1 at the specified positions for each column\n",
    "    for m in range(1, matrix_size + 1):\n",
    "        reflected_position = reflect(n, m)\n",
    "        reflection_matrix = reflection_matrix.at[reflected_position - 1, m - 1].set(\n",
    "            1\n",
    "        )  # Adjust for 0-based indexing\n",
    "\n",
    "    return reflection_matrix\n",
    "\n",
    "\n",
    "def generate_d4_matrices(n):\n",
    "    \"\"\"Outputs n^2 by n^2 matrices\"\"\"\n",
    "    # Get rotation and reflection matrices\n",
    "    R = generate_rotation_matrix(n)\n",
    "    S = generate_reflection_matrix(n)\n",
    "\n",
    "    # Calculate R^2, R^3, SR, SR^2, SR^3\n",
    "    R2 = jnp.dot(R, R)\n",
    "    R3 = jnp.dot(R2, R)\n",
    "    SR = jnp.dot(S, R)\n",
    "    SR2 = jnp.dot(S, R2)\n",
    "    SR3 = jnp.dot(S, R3)\n",
    "\n",
    "    # Generate D4 matrices\n",
    "    D4_matrices = [jnp.eye(n**2), R, R2, R3, S, SR, SR2, SR3]\n",
    "\n",
    "    return D4_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformation(image, transformation_matrix, n):\n",
    "    flat_image = image.flatten()\n",
    "    transformed_flat_image = jnp.dot(transformation_matrix, flat_image)\n",
    "    return transformed_flat_image.reshape((n, n))\n",
    "\n",
    "\n",
    "def apply_transformation_tf(image, matrix, n):\n",
    "    flat_image = tf.reshape(image, [n**2])\n",
    "    transformed_flat_image = tf.linalg.matvec(matrix, flat_image)\n",
    "    transformed_image = tf.reshape(transformed_flat_image, [n, n, 1])\n",
    "    return transformed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "d4_matrices = generate_d4_matrices(n)\n",
    "tf_d4_matrices = [tf.convert_to_tensor(matrix, dtype=tf.float32) for matrix in d4_matrices]\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "\n",
    "print(len(filtered_images))\n",
    "\n",
    "for img, lbl in zip(filtered_images, filtered_labels):\n",
    "    for matrix in d4_matrices:\n",
    "        transformed_image = apply_transformation(img, matrix, 8)\n",
    "        augmented_images.append(transformed_image)\n",
    "        augmented_labels.append(lbl)\n",
    "\n",
    "\n",
    "augmented_images = np.array(augmented_images)\n",
    "augmented_labels = np.array(augmented_labels)\n",
    "\n",
    "print(f\"augmented images shape: {augmented_images.shape}\")\n",
    "print(f\"aumented labels shape: {augmented_labels.shape}\")\n",
    "\n",
    "num_augmented_images = len(augmented_images)\n",
    "print(f\"Number of augmented images: {num_augmented_images}\")\n",
    "\n",
    "unique_augmented, counts_augmented = np.unique(augmented_labels, return_counts=True)\n",
    "augmented_class_distribution = dict(zip(unique_augmented, counts_augmented))\n",
    "print(\"Augmented class distribution:\", augmented_class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images_reshaped = augmented_images.reshape(-1, 8, 8, 1)\n",
    "print(augmented_images_reshaped.shape)\n",
    "print(augmented_labels.shape)\n",
    "X_train_aug, X_test_aug, Y_train_aug, Y_test_aug = train_test_split(\n",
    "    augmented_images_reshaped,\n",
    "    augmented_labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=augmented_labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformation_batch(inputs, matrix):\n",
    "    transformed = tf.map_fn(\n",
    "        lambda x: apply_transformation_tf(x, matrix, 8),\n",
    "        inputs,\n",
    "    )\n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConvLayer(layers.Layer):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(CustomConvLayer, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(kernel_size, kernel_size, 1, 1),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        convolved_results = []\n",
    "\n",
    "        for matrix in tf_d4_matrices:\n",
    "            transformed_inputs = apply_transformation_batch(inputs, matrix)\n",
    "            convolved = tf.nn.conv2d(\n",
    "                transformed_inputs, self.kernel, strides=[1, 1, 1, 1], padding=\"SAME\"\n",
    "            )\n",
    "            convolved_results.append(convolved)\n",
    "\n",
    "        convolved_average = tf.reduce_mean(tf.stack(convolved_results), axis=0)\n",
    "        return convolved_average\n",
    "\n",
    "\n",
    "class CustomPoolingLayer(layers.Layer):\n",
    "    def __init__(self, pool_size):\n",
    "        super(CustomPoolingLayer, self).__init__()\n",
    "        self.pool_size = pool_size\n",
    "\n",
    "    def call(self, inputs):\n",
    "        res = tf.nn.avg_pool(\n",
    "            inputs,\n",
    "            ksize=[1, self.pool_size[0], self.pool_size[1], 1],\n",
    "            strides=[1, self.pool_size[0], self.pool_size[1], 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 7\n",
    "\n",
    "model = models.Sequential(\n",
    "    [\n",
    "        CustomConvLayer(kernel_size=kernel_size),\n",
    "        CustomPoolingLayer(pool_size=(4, 4)),\n",
    "        layers.Flatten(),\n",
    "        layers.Activation(\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=32)\n",
    "print(\"Model training complete.\")\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "aug_model = models.Sequential(\n",
    "    [\n",
    "        CustomConvLayer(kernel_size=kernel_size),\n",
    "        CustomPoolingLayer(pool_size=(4, 4)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_circulant_matrix(kernel, image_size=8):\n",
    "    kernel_size = kernel.shape[0]\n",
    "    pad = kernel_size // 2\n",
    "\n",
    "    circ_matrix_size = image_size * image_size\n",
    "    circ_matrix = np.zeros((circ_matrix_size, circ_matrix_size))\n",
    "\n",
    "    for i in range(image_size):\n",
    "        for j in range(image_size):\n",
    "            row = np.zeros((image_size, image_size))\n",
    "            for ki in range(kernel_size):\n",
    "                for kj in range(kernel_size):\n",
    "                    ii = i + ki - pad\n",
    "                    jj = j + kj - pad\n",
    "                    if 0 <= ii < image_size and 0 <= jj < image_size:\n",
    "                        row[ii, jj] = kernel[ki, kj]\n",
    "            circ_matrix[i * image_size + j, :] = row.flatten()\n",
    "\n",
    "    return circ_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_averaged_kernel(kernel):\n",
    "    rotated_kernels = []\n",
    "    for matrix in d4_matrices:\n",
    "        rotated_kernel = kernel @ matrix\n",
    "        rotated_kernels.append(rotated_kernel)\n",
    "    averaged_kernel = tf.reduce_mean(tf.stack(rotated_kernels), axis=0)\n",
    "    return averaged_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kernel = np.random.randn(64, 64)\n",
    "averaged_test_kernel = create_averaged_kernel(test_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_matrix = tf.reshape(model.layers[0].kernel, [kernel_size, kernel_size])\n",
    "kernel_circulant_matrix = create_circulant_matrix(kernel_matrix)\n",
    "\n",
    "rotated_kernels = []\n",
    "for matrix in tf_d4_matrices:\n",
    "    rotated_kernel = kernel_circulant_matrix @ matrix\n",
    "    rotated_kernels.append(rotated_kernel)\n",
    "\n",
    "averaged_circulant_kernel = tf.reduce_mean(tf.stack(rotated_kernels), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_circulant_kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_combined_matrix(matrix, title=\"Combined Transformation Matrix\", width=20, height=16, title_fontsize=18, axis_fontsize=14, cbar_label=\"Color Bar Label\", cbar_tick_fontsize=14):\n",
    "    plt.figure(figsize=(width, height))\n",
    "    ax = sns.heatmap(matrix, annot=False, fmt=\".2f\", cmap=\"viridis\")\n",
    "    plt.title(title, fontsize=title_fontsize)\n",
    "    plt.tick_params(axis='x', labelsize=axis_fontsize)\n",
    "    plt.tick_params(axis='y', labelsize=axis_fontsize)\n",
    "\n",
    "    colorbar = ax.collections[0].colorbar\n",
    "\n",
    "    colorbar.ax.tick_params(labelsize=cbar_tick_fontsize)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_combined_matrix(\n",
    "    kernel_matrix, title=\"Convolution Kernel\", title_fontsize=60, axis_fontsize=50, cbar_tick_fontsize=50, height=32, width=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_combined_matrix(\n",
    "    kernel_circulant_matrix, title=\"Pre-Transformed Circulant Kernel\", title_fontsize=60, axis_fontsize=20, cbar_tick_fontsize=50, height=32, width=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_combined_matrix(\n",
    "    averaged_circulant_kernel, title=\"Transformed Circulant Kernel\", title_fontsize=60, axis_fontsize=20, cbar_tick_fontsize=50, height=32, width=40\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 - COB\n",
    "\n",
    "We have the averaged_circulant_kernel. Now we get the change of basis matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy.parsing.sympy_parser import parse_expr\n",
    "\n",
    "with open('8x8COB.txt', 'r') as f:\n",
    "    Q = [next(f) for _ in range(129)] # f.read()\n",
    "Q = [parse_expr(s.strip('\\n')) for s in Q if s != '\\n']\n",
    "Q = Q[1:] # Remove constant\n",
    "Q1, Q2, Q3, Q4, Q56, Q78 = Q[:10], Q[10:16], Q[16:22], Q[22:32], Q[32:48], Q[48:]\n",
    "Q1, Q2, Q3, Q4, Q56, Q78 = [elem[0,0] for elem in Q1], [elem[1,0] for elem in Q2], [elem[2,0] for elem in Q3], [elem[3,0] for elem in Q4], [elem[(4,5),0].tolist() for elem in Q56], [elem[(6,7),0].tolist() for elem in Q78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "Q1_Str = [[elem.replace('x','') for elem in l] for l in [str(q).split(' + ') for q in Q1]]\n",
    "Q2_str = [str(q).replace(' - ',' + -') for q in Q2]\n",
    "Q2_Str = [[elem.replace('x','') for elem in l] for l in [str(q).split(' + ') for q in Q2_str]]\n",
    "Q3_str = [str(q).replace(' - ',' + -') for q in Q3]\n",
    "Q3_Str = [[elem.replace('x','') for elem in l] for l in [str(q).split(' + ') for q in Q3_str]]\n",
    "Q4_str = [str(q).replace(' - ',' + -') for q in Q4]\n",
    "Q4_Str = [[elem.replace('x','') for elem in l] for l in [str(q).split(' + ') for q in Q4_str]]\n",
    "Q56_str = [(str(q[0]).replace(' - ',' + -'),str(q[1]).replace(' - ',' + -')) for q in Q56]\n",
    "Q56_Str = [[[elem.replace('x','').replace('[','').replace(']','') for elem in l0],[elem.replace('x','').replace('[','').replace(']','') for elem in l1]] for l0,l1 in [(q[0].split(' + '),q[1].split(' + ')) for q in Q56_str]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import copysign\n",
    "\n",
    "X_matrix = jnp.zeros((64,64))\n",
    "\n",
    "Q1_to_4 = Q1_Str + Q2_Str + Q3_Str + Q4_Str\n",
    "\n",
    "for i in range(32):\n",
    "  for elem in Q1_to_4[i]:\n",
    "    X_matrix = X_matrix.at[i,abs(int(elem))-1].set(np.sign(int(elem))*1)\n",
    "\n",
    "for i in range(16):\n",
    "  for elem in Q56_Str[i][0]:\n",
    "    X_matrix = X_matrix.at[i+32,abs(int(elem))-1].set(np.sign(int(elem))*1)\n",
    "  for elem in Q56_Str[i][1]:\n",
    "    X_matrix = X_matrix.at[i+48,abs(int(elem))-1].set(np.sign(int(elem))*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = X_matrix.copy()\n",
    "plt.imshow(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_combined_matrix(\n",
    "    B, title=\"Change of Basis Matrix\", title_fontsize=60, axis_fontsize=20, cbar_tick_fontsize=50, height=32, width=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array(B)\n",
    "B_inv = np.linalg.inv(B)\n",
    "M = averaged_circulant_kernel @ B_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_combined_matrix(\n",
    "    B_inv, title=\"Inverse Change of Basis Matrix\", title_fontsize=60, axis_fontsize=20, cbar_tick_fontsize=50, height=32, width=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_combined_matrix(\n",
    "    M, title=\"Linear Map on Fundamental Invariants\", title_fontsize=60, axis_fontsize=20, cbar_tick_fontsize=50, height=32, width=40\n",
    ")\n",
    "visualize_combined_matrix(\n",
    "    averaged_circulant_kernel, title=\"Transformed Circulant Kernel\", title_fontsize=50, axis_fontsize=20, cbar_tick_fontsize=20, height=32, width=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_combined_matrix(averaged_test_kernel @ B_inv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
